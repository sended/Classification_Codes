{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv('Iris.csv')\n",
    "iris.drop(['Id'], axis = 1, inplace = True)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(iris.drop(['Species'], axis =1), iris.Species, test_size= 0.25, \n",
    "                                                stratify = iris['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_test = {\n",
    "    'n_estimators':[5,10,20,40,100],\n",
    "    'criterion':['gini', 'entropy'],\n",
    "    #'max_features':[int, float, 'sqrt', 'log2', None],\n",
    "    'max_depth':[None, 3, 4, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificator = RandomForestClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator= classificator, param_grid= parameters_test, scoring= 'accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [5, 10, 20, 40, 100], 'criterion': ['gini', 'entropy'], 'max_depth': [None, 3, 4, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0        0.111754  8.138577e-04         0.112271    1.241047e-03   \n",
      "1        0.113736  8.137158e-04         0.116601    1.693851e-03   \n",
      "2        0.116061  3.291508e-03         0.120259    1.694516e-03   \n",
      "3        0.126699  5.619580e-07         0.121921    6.743496e-07   \n",
      "4        0.154746  2.859668e-03         0.103029    6.836514e-07   \n",
      "5        0.110866  2.712222e-03         0.102361    2.326506e-04   \n",
      "6        0.108206  8.141990e-04         0.103029    7.370010e-07   \n",
      "7        0.113193  4.899036e-07         0.103029    8.778064e-07   \n",
      "8        0.116367  9.570706e-04         0.103608    4.650503e-04   \n",
      "9        0.142517  4.697970e-04         0.105031    9.413921e-04   \n",
      "10       0.107747  2.973602e-07         0.102316    2.955963e-05   \n",
      "11       0.110074  4.704150e-04         0.104899    1.072147e-06   \n",
      "12       0.110038  4.694206e-04         0.104113    3.113491e-05   \n",
      "13       0.115716  1.410683e-03         0.102954    1.959614e-06   \n",
      "14       0.132813  8.015348e-04         0.105287    9.241494e-04   \n",
      "15       0.106468  4.706986e-04         0.104377    9.391455e-04   \n",
      "16       0.107455  4.700779e-04         0.105110    1.387069e-05   \n",
      "17       0.109449  4.697412e-04         0.105098    2.727668e-06   \n",
      "18       0.115695  1.681379e-03         0.103760    7.704486e-04   \n",
      "19       0.134050  8.144915e-04         0.114994    4.046097e-06   \n",
      "20       0.106094  4.575464e-04         0.102759    8.485379e-07   \n",
      "21       0.107031  1.520405e-06         0.105098    4.831715e-04   \n",
      "22       0.110275  1.250516e-04         0.103701    9.064562e-04   \n",
      "23       0.115724  1.946680e-07         0.102969    1.946680e-07   \n",
      "24       0.136781  4.948317e-03         0.104760    2.606163e-03   \n",
      "25       0.106200  4.701903e-04         0.102444    1.946680e-07   \n",
      "26       0.107875  1.418318e-05         0.103096    4.841303e-04   \n",
      "27       0.122375  6.147053e-03         0.103221    4.705274e-04   \n",
      "28       0.117415  9.382516e-04         0.104077    8.161454e-04   \n",
      "29       0.142739  1.695607e-03         0.103045    4.706401e-04   \n",
      "30       0.107556  4.713178e-04         0.102324    4.725506e-04   \n",
      "31       0.108089  1.184972e-05         0.109458    9.437647e-04   \n",
      "32       0.109366  4.803617e-04         0.102991    1.123916e-07   \n",
      "33       0.115031  4.701903e-04         0.102852    1.520405e-06   \n",
      "34       0.133478  4.505318e-04         0.115733    1.401671e-03   \n",
      "35       0.105651  4.713154e-04         0.102632    1.325077e-06   \n",
      "36       0.106819  4.701340e-04         0.105708    1.483569e-05   \n",
      "37       0.109651  4.586711e-04         0.106024    4.679427e-04   \n",
      "38       0.122671  4.534822e-03         0.115927    7.805165e-04   \n",
      "39       0.143246  5.553795e-03         0.112131    1.892125e-03   \n",
      "\n",
      "   param_criterion param_max_depth param_n_estimators  \\\n",
      "0             gini            None                  5   \n",
      "1             gini            None                 10   \n",
      "2             gini            None                 20   \n",
      "3             gini            None                 40   \n",
      "4             gini            None                100   \n",
      "5             gini               3                  5   \n",
      "6             gini               3                 10   \n",
      "7             gini               3                 20   \n",
      "8             gini               3                 40   \n",
      "9             gini               3                100   \n",
      "10            gini               4                  5   \n",
      "11            gini               4                 10   \n",
      "12            gini               4                 20   \n",
      "13            gini               4                 40   \n",
      "14            gini               4                100   \n",
      "15            gini              10                  5   \n",
      "16            gini              10                 10   \n",
      "17            gini              10                 20   \n",
      "18            gini              10                 40   \n",
      "19            gini              10                100   \n",
      "20         entropy            None                  5   \n",
      "21         entropy            None                 10   \n",
      "22         entropy            None                 20   \n",
      "23         entropy            None                 40   \n",
      "24         entropy            None                100   \n",
      "25         entropy               3                  5   \n",
      "26         entropy               3                 10   \n",
      "27         entropy               3                 20   \n",
      "28         entropy               3                 40   \n",
      "29         entropy               3                100   \n",
      "30         entropy               4                  5   \n",
      "31         entropy               4                 10   \n",
      "32         entropy               4                 20   \n",
      "33         entropy               4                 40   \n",
      "34         entropy               4                100   \n",
      "35         entropy              10                  5   \n",
      "36         entropy              10                 10   \n",
      "37         entropy              10                 20   \n",
      "38         entropy              10                 40   \n",
      "39         entropy              10                100   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "0   {'criterion': 'gini', 'max_depth': None, 'n_es...           0.974359   \n",
      "1   {'criterion': 'gini', 'max_depth': None, 'n_es...           0.974359   \n",
      "2   {'criterion': 'gini', 'max_depth': None, 'n_es...           1.000000   \n",
      "3   {'criterion': 'gini', 'max_depth': None, 'n_es...           0.974359   \n",
      "4   {'criterion': 'gini', 'max_depth': None, 'n_es...           0.974359   \n",
      "5   {'criterion': 'gini', 'max_depth': 3, 'n_estim...           0.974359   \n",
      "6   {'criterion': 'gini', 'max_depth': 3, 'n_estim...           0.974359   \n",
      "7   {'criterion': 'gini', 'max_depth': 3, 'n_estim...           0.974359   \n",
      "8   {'criterion': 'gini', 'max_depth': 3, 'n_estim...           1.000000   \n",
      "9   {'criterion': 'gini', 'max_depth': 3, 'n_estim...           0.974359   \n",
      "10  {'criterion': 'gini', 'max_depth': 4, 'n_estim...           0.974359   \n",
      "11  {'criterion': 'gini', 'max_depth': 4, 'n_estim...           0.974359   \n",
      "12  {'criterion': 'gini', 'max_depth': 4, 'n_estim...           0.974359   \n",
      "13  {'criterion': 'gini', 'max_depth': 4, 'n_estim...           0.974359   \n",
      "14  {'criterion': 'gini', 'max_depth': 4, 'n_estim...           0.974359   \n",
      "15  {'criterion': 'gini', 'max_depth': 10, 'n_esti...           0.948718   \n",
      "16  {'criterion': 'gini', 'max_depth': 10, 'n_esti...           0.974359   \n",
      "17  {'criterion': 'gini', 'max_depth': 10, 'n_esti...           0.974359   \n",
      "18  {'criterion': 'gini', 'max_depth': 10, 'n_esti...           0.974359   \n",
      "19  {'criterion': 'gini', 'max_depth': 10, 'n_esti...           0.974359   \n",
      "20  {'criterion': 'entropy', 'max_depth': None, 'n...           0.974359   \n",
      "21  {'criterion': 'entropy', 'max_depth': None, 'n...           0.897436   \n",
      "22  {'criterion': 'entropy', 'max_depth': None, 'n...           0.974359   \n",
      "23  {'criterion': 'entropy', 'max_depth': None, 'n...           0.974359   \n",
      "24  {'criterion': 'entropy', 'max_depth': None, 'n...           0.974359   \n",
      "25  {'criterion': 'entropy', 'max_depth': 3, 'n_es...           0.974359   \n",
      "26  {'criterion': 'entropy', 'max_depth': 3, 'n_es...           0.974359   \n",
      "27  {'criterion': 'entropy', 'max_depth': 3, 'n_es...           0.974359   \n",
      "28  {'criterion': 'entropy', 'max_depth': 3, 'n_es...           0.974359   \n",
      "29  {'criterion': 'entropy', 'max_depth': 3, 'n_es...           0.974359   \n",
      "30  {'criterion': 'entropy', 'max_depth': 4, 'n_es...           0.948718   \n",
      "31  {'criterion': 'entropy', 'max_depth': 4, 'n_es...           0.948718   \n",
      "32  {'criterion': 'entropy', 'max_depth': 4, 'n_es...           0.974359   \n",
      "33  {'criterion': 'entropy', 'max_depth': 4, 'n_es...           0.974359   \n",
      "34  {'criterion': 'entropy', 'max_depth': 4, 'n_es...           0.974359   \n",
      "35  {'criterion': 'entropy', 'max_depth': 10, 'n_e...           0.974359   \n",
      "36  {'criterion': 'entropy', 'max_depth': 10, 'n_e...           0.974359   \n",
      "37  {'criterion': 'entropy', 'max_depth': 10, 'n_e...           0.974359   \n",
      "38  {'criterion': 'entropy', 'max_depth': 10, 'n_e...           0.974359   \n",
      "39  {'criterion': 'entropy', 'max_depth': 10, 'n_e...           0.974359   \n",
      "\n",
      "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
      "0            0.945946           1.000000         0.973214        0.021834   \n",
      "1            0.945946           1.000000         0.973214        0.021834   \n",
      "2            0.945946           1.000000         0.982143        0.025424   \n",
      "3            0.945946           1.000000         0.973214        0.021834   \n",
      "4            0.945946           1.000000         0.973214        0.021834   \n",
      "5            0.972973           0.972222         0.973214        0.000890   \n",
      "6            0.945946           0.972222         0.964286        0.012911   \n",
      "7            0.945946           0.972222         0.964286        0.012911   \n",
      "8            0.945946           1.000000         0.982143        0.025424   \n",
      "9            0.945946           1.000000         0.973214        0.021834   \n",
      "10           0.972973           1.000000         0.982143        0.012303   \n",
      "11           0.972973           1.000000         0.982143        0.012303   \n",
      "12           0.945946           1.000000         0.973214        0.021834   \n",
      "13           0.945946           0.972222         0.964286        0.012911   \n",
      "14           0.945946           1.000000         0.973214        0.021834   \n",
      "15           0.945946           1.000000         0.964286        0.024607   \n",
      "16           0.945946           1.000000         0.973214        0.021834   \n",
      "17           0.972973           1.000000         0.982143        0.012303   \n",
      "18           0.945946           1.000000         0.973214        0.021834   \n",
      "19           0.945946           0.972222         0.964286        0.012911   \n",
      "20           0.972973           1.000000         0.982143        0.012303   \n",
      "21           0.945946           0.972222         0.937500        0.031145   \n",
      "22           0.972973           1.000000         0.982143        0.012303   \n",
      "23           0.945946           0.972222         0.964286        0.012911   \n",
      "24           0.945946           1.000000         0.973214        0.021834   \n",
      "25           0.972973           0.972222         0.973214        0.000890   \n",
      "26           0.945946           0.972222         0.964286        0.012911   \n",
      "27           0.945946           0.972222         0.964286        0.012911   \n",
      "28           0.945946           1.000000         0.973214        0.021834   \n",
      "29           0.945946           0.972222         0.964286        0.012911   \n",
      "30           0.945946           0.972222         0.955357        0.011663   \n",
      "31           0.972973           0.972222         0.964286        0.011383   \n",
      "32           0.972973           1.000000         0.982143        0.012303   \n",
      "33           0.945946           1.000000         0.973214        0.021834   \n",
      "34           0.945946           1.000000         0.973214        0.021834   \n",
      "35           0.972973           1.000000         0.982143        0.012303   \n",
      "36           0.972973           1.000000         0.982143        0.012303   \n",
      "37           0.945946           1.000000         0.973214        0.021834   \n",
      "38           0.945946           1.000000         0.973214        0.021834   \n",
      "39           0.945946           1.000000         0.973214        0.021834   \n",
      "\n",
      "    rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                11            1.000000            1.000000   \n",
      "1                11            0.986301            1.000000   \n",
      "2                 1            0.986301            1.000000   \n",
      "3                11            1.000000            1.000000   \n",
      "4                11            1.000000            1.000000   \n",
      "5                11            1.000000            1.000000   \n",
      "6                29            1.000000            1.000000   \n",
      "7                29            0.986301            1.000000   \n",
      "8                 1            0.986301            1.000000   \n",
      "9                11            1.000000            1.000000   \n",
      "10                1            0.986301            1.000000   \n",
      "11                1            1.000000            1.000000   \n",
      "12               11            1.000000            1.000000   \n",
      "13               29            1.000000            1.000000   \n",
      "14               11            1.000000            1.000000   \n",
      "15               29            1.000000            1.000000   \n",
      "16               11            1.000000            1.000000   \n",
      "17                1            1.000000            1.000000   \n",
      "18               11            1.000000            1.000000   \n",
      "19               29            1.000000            1.000000   \n",
      "20                1            0.986301            0.986667   \n",
      "21               40            1.000000            1.000000   \n",
      "22                1            1.000000            1.000000   \n",
      "23               29            1.000000            1.000000   \n",
      "24               11            1.000000            1.000000   \n",
      "25               11            0.986301            1.000000   \n",
      "26               29            0.986301            1.000000   \n",
      "27               29            0.986301            1.000000   \n",
      "28               11            1.000000            1.000000   \n",
      "29               29            0.986301            1.000000   \n",
      "30               39            1.000000            1.000000   \n",
      "31               29            1.000000            1.000000   \n",
      "32                1            1.000000            1.000000   \n",
      "33               11            1.000000            1.000000   \n",
      "34               11            1.000000            1.000000   \n",
      "35                1            1.000000            1.000000   \n",
      "36                1            1.000000            1.000000   \n",
      "37               11            1.000000            1.000000   \n",
      "38               11            1.000000            1.000000   \n",
      "39               11            1.000000            1.000000   \n",
      "\n",
      "    split2_train_score  mean_train_score  std_train_score  \n",
      "0             1.000000          1.000000         0.000000  \n",
      "1             1.000000          0.995434         0.006458  \n",
      "2             1.000000          0.995434         0.006458  \n",
      "3             1.000000          1.000000         0.000000  \n",
      "4             1.000000          1.000000         0.000000  \n",
      "5             0.986842          0.995614         0.006203  \n",
      "6             0.986842          0.995614         0.006203  \n",
      "7             0.986842          0.991048         0.006334  \n",
      "8             1.000000          0.995434         0.006458  \n",
      "9             1.000000          1.000000         0.000000  \n",
      "10            0.986842          0.991048         0.006334  \n",
      "11            1.000000          1.000000         0.000000  \n",
      "12            1.000000          1.000000         0.000000  \n",
      "13            1.000000          1.000000         0.000000  \n",
      "14            1.000000          1.000000         0.000000  \n",
      "15            1.000000          1.000000         0.000000  \n",
      "16            1.000000          1.000000         0.000000  \n",
      "17            1.000000          1.000000         0.000000  \n",
      "18            1.000000          1.000000         0.000000  \n",
      "19            1.000000          1.000000         0.000000  \n",
      "20            0.986842          0.986603         0.000225  \n",
      "21            0.986842          0.995614         0.006203  \n",
      "22            1.000000          1.000000         0.000000  \n",
      "23            1.000000          1.000000         0.000000  \n",
      "24            1.000000          1.000000         0.000000  \n",
      "25            0.986842          0.991048         0.006334  \n",
      "26            0.986842          0.991048         0.006334  \n",
      "27            0.986842          0.991048         0.006334  \n",
      "28            1.000000          1.000000         0.000000  \n",
      "29            0.986842          0.991048         0.006334  \n",
      "30            1.000000          1.000000         0.000000  \n",
      "31            1.000000          1.000000         0.000000  \n",
      "32            1.000000          1.000000         0.000000  \n",
      "33            1.000000          1.000000         0.000000  \n",
      "34            1.000000          1.000000         0.000000  \n",
      "35            1.000000          1.000000         0.000000  \n",
      "36            1.000000          1.000000         0.000000  \n",
      "37            1.000000          1.000000         0.000000  \n",
      "38            1.000000          1.000000         0.000000  \n",
      "39            1.000000          1.000000         0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(grid.cv_results_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': None, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificator = RandomForestClassifier(criterion='gini', n_estimators=20, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificator.fit(trainX, trainY)\n",
    "predict = classificator.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 11  2]\n",
      " [ 0  2 10]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        13\n",
      "Iris-versicolor       0.85      0.85      0.85        13\n",
      " Iris-virginica       0.83      0.83      0.83        12\n",
      "\n",
      "      micro avg       0.89      0.89      0.89        38\n",
      "      macro avg       0.89      0.89      0.89        38\n",
      "   weighted avg       0.89      0.89      0.89        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(testY, predict))\n",
    "print(classification_report(testY, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 4 artists>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.barh(iris.columns[:-1], classificator.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(iris.drop(['Species', 'SepalWidthCm', 'SepalLengthCm'], axis =1), iris.Species, test_size= 0.25, \n",
    "                                                stratify = iris['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0 12]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        13\n",
      "Iris-versicolor       1.00      0.92      0.96        13\n",
      " Iris-virginica       0.92      1.00      0.96        12\n",
      "\n",
      "      micro avg       0.97      0.97      0.97        38\n",
      "      macro avg       0.97      0.97      0.97        38\n",
      "   weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classificator = RandomForestClassifier(criterion='gini', n_estimators=20, n_jobs=-1)\n",
    "classificator.fit(trainX, trainY)\n",
    "predict = classificator.predict(testX)\n",
    "print(confusion_matrix(testY, predict))\n",
    "print(classification_report(testY, predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
