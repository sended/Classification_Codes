{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv('Iris.csv')\n",
    "iris.drop(['Id'], axis = 1, inplace = True)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(iris.drop(['Species'], axis =1), iris.Species, test_size= 0.25, \n",
    "                                                stratify = iris['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentun = lambda l : list(np.array(l) / 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "momentun([10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_test = {\n",
    "    'hidden_layer_sizes':[(10,), (10,5), (20,), (20, 10), (40, 20, 10)],\n",
    "    'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver':['lbfgs', 'sgd', 'adam'],\n",
    "    'momentum': momentun(list(range(10, 100, 10)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificator = MLPClassifier(tol=0.0000001, max_iter= 1400)\n",
    "grid = GridSearchCV(classificator, parameters_test, scoring= 'accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1400) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1400, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=1e-07,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': [(10,), (10, 5), (20,), (20, 10), (40, 20, 10)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'momentum': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0         0.064827      0.028986         0.001662    4.697969e-04   \n",
      "1         0.512649      0.008579         0.001662    4.696845e-04   \n",
      "2         0.549219      0.001695         0.001995    7.018853e-07   \n",
      "3         0.035572      0.022469         0.001662    4.704712e-04   \n",
      "4         0.526280      0.005777         0.001995    8.139067e-04   \n",
      "5         0.563180      0.008475         0.001662    4.700217e-04   \n",
      "6         0.065823      0.023305         0.001994    1.946680e-07   \n",
      "7         0.517616      0.004309         0.001662    4.703588e-04   \n",
      "8         0.562828      0.016775         0.001330    4.705837e-04   \n",
      "9         0.067153      0.031426         0.000998    4.052337e-07   \n",
      "10        0.520276      0.012224         0.003324    3.290995e-03   \n",
      "11        0.537915      0.007697         0.000997    2.973602e-07   \n",
      "12        0.034574      0.022979         0.001330    4.697407e-04   \n",
      "13        0.509167      0.002821         0.000997    1.946680e-07   \n",
      "14        0.545736      0.028748         0.001330    4.698532e-04   \n",
      "15        0.052871      0.031239         0.001330    4.698532e-04   \n",
      "16        0.503333      0.004079         0.000997    3.893359e-07   \n",
      "17        0.536408      0.002618         0.001662    4.700779e-04   \n",
      "18        0.038231      0.014345         0.001330    4.701903e-04   \n",
      "19        0.519960      0.012251         0.001330    4.701341e-04   \n",
      "20        0.543895      0.009646         0.001662    4.702464e-04   \n",
      "21        0.049534      0.021240         0.000997    3.371748e-07   \n",
      "22        0.526777      0.009108         0.000997    1.123916e-07   \n",
      "23        0.541742      0.009951         0.000998    8.485379e-07   \n",
      "24        0.031582      0.017736         0.000997    2.973602e-07   \n",
      "25        0.500537      0.000626         0.001014    2.264879e-05   \n",
      "26        0.538775      0.015328         0.001995    2.973602e-07   \n",
      "27        0.133492      0.136221         0.000997    2.247832e-07   \n",
      "28        0.585648      0.005890         0.000998    0.000000e+00   \n",
      "29        0.655291      0.012537         0.000997    1.123916e-07   \n",
      "..             ...           ...              ...             ...   \n",
      "510       0.115208      0.053165         0.001328    4.708675e-04   \n",
      "511       0.683868      0.006258         0.001330    4.702466e-04   \n",
      "512       0.771138      0.004724         0.001662    4.701341e-04   \n",
      "513       0.079623      0.008771         0.001330    4.701342e-04   \n",
      "514       0.888004      0.003462         0.001330    4.697408e-04   \n",
      "515       0.731248      0.068555         0.001662    4.704150e-04   \n",
      "516       0.097575      0.035280         0.000997    4.495664e-07   \n",
      "517       0.895681      0.017803         0.001330    4.704150e-04   \n",
      "518       0.771156      0.036866         0.001504    4.072807e-04   \n",
      "519       0.118357      0.030636         0.001330    4.703026e-04   \n",
      "520       0.898171      0.004072         0.000997    6.257699e-07   \n",
      "521       0.853284      0.102021         0.001330    4.703026e-04   \n",
      "522       0.061510      0.013646         0.000997    1.946680e-07   \n",
      "523       0.889505      0.005298         0.001662    4.702464e-04   \n",
      "524       0.983587      0.029275         0.000997    3.893359e-07   \n",
      "525       0.127828      0.063544         0.001330    4.699655e-04   \n",
      "526       0.914440      0.014666         0.001662    4.700779e-04   \n",
      "527       0.793754      0.167582         0.001170    2.449013e-04   \n",
      "528       0.164065      0.091692         0.001994    4.052337e-07   \n",
      "529       0.893878      0.012676         0.001662    4.696283e-04   \n",
      "530       0.886232      0.104074         0.001330    4.699655e-04   \n",
      "531       0.098905      0.051691         0.001330    4.699657e-04   \n",
      "532       0.897197      0.007943         0.001330    4.694035e-04   \n",
      "533       1.012546      0.026754         0.001330    4.696848e-04   \n",
      "534       0.141961      0.040783         0.001663    4.701340e-04   \n",
      "535       0.893660      0.010846         0.000998    1.946680e-07   \n",
      "536       0.875467      0.044692         0.001001    3.685005e-06   \n",
      "537       0.185517      0.117235         0.001663    4.703027e-04   \n",
      "538       0.788064      0.024355         0.000991    8.499510e-06   \n",
      "539       0.596964      0.143363         0.000664    4.696291e-04   \n",
      "\n",
      "    param_activation param_hidden_layer_sizes param_momentum param_solver  \\\n",
      "0           identity                    (10,)            0.1        lbfgs   \n",
      "1           identity                    (10,)            0.1          sgd   \n",
      "2           identity                    (10,)            0.1         adam   \n",
      "3           identity                    (10,)            0.2        lbfgs   \n",
      "4           identity                    (10,)            0.2          sgd   \n",
      "5           identity                    (10,)            0.2         adam   \n",
      "6           identity                    (10,)            0.3        lbfgs   \n",
      "7           identity                    (10,)            0.3          sgd   \n",
      "8           identity                    (10,)            0.3         adam   \n",
      "9           identity                    (10,)            0.4        lbfgs   \n",
      "10          identity                    (10,)            0.4          sgd   \n",
      "11          identity                    (10,)            0.4         adam   \n",
      "12          identity                    (10,)            0.5        lbfgs   \n",
      "13          identity                    (10,)            0.5          sgd   \n",
      "14          identity                    (10,)            0.5         adam   \n",
      "15          identity                    (10,)            0.6        lbfgs   \n",
      "16          identity                    (10,)            0.6          sgd   \n",
      "17          identity                    (10,)            0.6         adam   \n",
      "18          identity                    (10,)            0.7        lbfgs   \n",
      "19          identity                    (10,)            0.7          sgd   \n",
      "20          identity                    (10,)            0.7         adam   \n",
      "21          identity                    (10,)            0.8        lbfgs   \n",
      "22          identity                    (10,)            0.8          sgd   \n",
      "23          identity                    (10,)            0.8         adam   \n",
      "24          identity                    (10,)            0.9        lbfgs   \n",
      "25          identity                    (10,)            0.9          sgd   \n",
      "26          identity                    (10,)            0.9         adam   \n",
      "27          identity                  (10, 5)            0.1        lbfgs   \n",
      "28          identity                  (10, 5)            0.1          sgd   \n",
      "29          identity                  (10, 5)            0.1         adam   \n",
      "..               ...                      ...            ...          ...   \n",
      "510             relu                 (20, 10)            0.9        lbfgs   \n",
      "511             relu                 (20, 10)            0.9          sgd   \n",
      "512             relu                 (20, 10)            0.9         adam   \n",
      "513             relu             (40, 20, 10)            0.1        lbfgs   \n",
      "514             relu             (40, 20, 10)            0.1          sgd   \n",
      "515             relu             (40, 20, 10)            0.1         adam   \n",
      "516             relu             (40, 20, 10)            0.2        lbfgs   \n",
      "517             relu             (40, 20, 10)            0.2          sgd   \n",
      "518             relu             (40, 20, 10)            0.2         adam   \n",
      "519             relu             (40, 20, 10)            0.3        lbfgs   \n",
      "520             relu             (40, 20, 10)            0.3          sgd   \n",
      "521             relu             (40, 20, 10)            0.3         adam   \n",
      "522             relu             (40, 20, 10)            0.4        lbfgs   \n",
      "523             relu             (40, 20, 10)            0.4          sgd   \n",
      "524             relu             (40, 20, 10)            0.4         adam   \n",
      "525             relu             (40, 20, 10)            0.5        lbfgs   \n",
      "526             relu             (40, 20, 10)            0.5          sgd   \n",
      "527             relu             (40, 20, 10)            0.5         adam   \n",
      "528             relu             (40, 20, 10)            0.6        lbfgs   \n",
      "529             relu             (40, 20, 10)            0.6          sgd   \n",
      "530             relu             (40, 20, 10)            0.6         adam   \n",
      "531             relu             (40, 20, 10)            0.7        lbfgs   \n",
      "532             relu             (40, 20, 10)            0.7          sgd   \n",
      "533             relu             (40, 20, 10)            0.7         adam   \n",
      "534             relu             (40, 20, 10)            0.8        lbfgs   \n",
      "535             relu             (40, 20, 10)            0.8          sgd   \n",
      "536             relu             (40, 20, 10)            0.8         adam   \n",
      "537             relu             (40, 20, 10)            0.9        lbfgs   \n",
      "538             relu             (40, 20, 10)            0.9          sgd   \n",
      "539             relu             (40, 20, 10)            0.9         adam   \n",
      "\n",
      "                                                params  split0_test_score  \\\n",
      "0    {'activation': 'identity', 'hidden_layer_sizes...           1.000000   \n",
      "1    {'activation': 'identity', 'hidden_layer_sizes...           0.974359   \n",
      "2    {'activation': 'identity', 'hidden_layer_sizes...           0.974359   \n",
      "3    {'activation': 'identity', 'hidden_layer_sizes...           1.000000   \n",
      "4    {'activation': 'identity', 'hidden_layer_sizes...           0.948718   \n",
      "5    {'activation': 'identity', 'hidden_layer_sizes...           0.948718   \n",
      "6    {'activation': 'identity', 'hidden_layer_sizes...           1.000000   \n",
      "7    {'activation': 'identity', 'hidden_layer_sizes...           0.948718   \n",
      "8    {'activation': 'identity', 'hidden_layer_sizes...           0.948718   \n",
      "9    {'activation': 'identity', 'hidden_layer_sizes...           1.000000   \n",
      "10   {'activation': 'identity', 'hidden_layer_sizes...           0.948718   \n",
      "11   {'activation': 'identity', 'hidden_layer_sizes...           0.948718   \n",
      "12   {'activation': 'identity', 'hidden_layer_sizes...           1.000000   \n",
      "13   {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "14   {'activation': 'identity', 'hidden_layer_sizes...           0.974359   \n",
      "15   {'activation': 'identity', 'hidden_layer_sizes...           1.000000   \n",
      "16   {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "17   {'activation': 'identity', 'hidden_layer_sizes...           0.974359   \n",
      "18   {'activation': 'identity', 'hidden_layer_sizes...           1.000000   \n",
      "19   {'activation': 'identity', 'hidden_layer_sizes...           0.974359   \n",
      "20   {'activation': 'identity', 'hidden_layer_sizes...           0.948718   \n",
      "21   {'activation': 'identity', 'hidden_layer_sizes...           1.000000   \n",
      "22   {'activation': 'identity', 'hidden_layer_sizes...           0.948718   \n",
      "23   {'activation': 'identity', 'hidden_layer_sizes...           0.948718   \n",
      "24   {'activation': 'identity', 'hidden_layer_sizes...           1.000000   \n",
      "25   {'activation': 'identity', 'hidden_layer_sizes...           0.974359   \n",
      "26   {'activation': 'identity', 'hidden_layer_sizes...           0.974359   \n",
      "27   {'activation': 'identity', 'hidden_layer_sizes...           1.000000   \n",
      "28   {'activation': 'identity', 'hidden_layer_sizes...           0.897436   \n",
      "29   {'activation': 'identity', 'hidden_layer_sizes...           0.974359   \n",
      "..                                                 ...                ...   \n",
      "510  {'activation': 'relu', 'hidden_layer_sizes': (...           0.948718   \n",
      "511  {'activation': 'relu', 'hidden_layer_sizes': (...           0.948718   \n",
      "512  {'activation': 'relu', 'hidden_layer_sizes': (...           1.000000   \n",
      "513  {'activation': 'relu', 'hidden_layer_sizes': (...           0.948718   \n",
      "514  {'activation': 'relu', 'hidden_layer_sizes': (...           0.948718   \n",
      "515  {'activation': 'relu', 'hidden_layer_sizes': (...           0.974359   \n",
      "516  {'activation': 'relu', 'hidden_layer_sizes': (...           0.897436   \n",
      "517  {'activation': 'relu', 'hidden_layer_sizes': (...           0.948718   \n",
      "518  {'activation': 'relu', 'hidden_layer_sizes': (...           0.974359   \n",
      "519  {'activation': 'relu', 'hidden_layer_sizes': (...           0.948718   \n",
      "520  {'activation': 'relu', 'hidden_layer_sizes': (...           0.948718   \n",
      "521  {'activation': 'relu', 'hidden_layer_sizes': (...           1.000000   \n",
      "522  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "523  {'activation': 'relu', 'hidden_layer_sizes': (...           0.948718   \n",
      "524  {'activation': 'relu', 'hidden_layer_sizes': (...           1.000000   \n",
      "525  {'activation': 'relu', 'hidden_layer_sizes': (...           0.974359   \n",
      "526  {'activation': 'relu', 'hidden_layer_sizes': (...           0.948718   \n",
      "527  {'activation': 'relu', 'hidden_layer_sizes': (...           1.000000   \n",
      "528  {'activation': 'relu', 'hidden_layer_sizes': (...           1.000000   \n",
      "529  {'activation': 'relu', 'hidden_layer_sizes': (...           0.974359   \n",
      "530  {'activation': 'relu', 'hidden_layer_sizes': (...           1.000000   \n",
      "531  {'activation': 'relu', 'hidden_layer_sizes': (...           0.948718   \n",
      "532  {'activation': 'relu', 'hidden_layer_sizes': (...           0.948718   \n",
      "533  {'activation': 'relu', 'hidden_layer_sizes': (...           0.897436   \n",
      "534  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "535  {'activation': 'relu', 'hidden_layer_sizes': (...           0.948718   \n",
      "536  {'activation': 'relu', 'hidden_layer_sizes': (...           1.000000   \n",
      "537  {'activation': 'relu', 'hidden_layer_sizes': (...           0.974359   \n",
      "538  {'activation': 'relu', 'hidden_layer_sizes': (...           0.948718   \n",
      "539  {'activation': 'relu', 'hidden_layer_sizes': (...           1.000000   \n",
      "\n",
      "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
      "0             0.945946           0.916667         0.955357        0.034705   \n",
      "1             0.972973           0.916667         0.955357        0.026635   \n",
      "2             1.000000           0.944444         0.973214        0.022439   \n",
      "3             0.945946           0.916667         0.955357        0.034705   \n",
      "4             0.918919           0.944444         0.937500        0.013167   \n",
      "5             1.000000           0.944444         0.964286        0.025146   \n",
      "6             0.945946           0.916667         0.955357        0.034705   \n",
      "7             0.918919           0.777778         0.883929        0.074081   \n",
      "8             1.000000           0.888889         0.946429        0.044879   \n",
      "9             0.945946           0.916667         0.955357        0.034705   \n",
      "10            0.891892           0.916667         0.919643        0.023487   \n",
      "11            1.000000           0.944444         0.964286        0.025146   \n",
      "12            0.945946           0.916667         0.955357        0.034705   \n",
      "13            1.000000           0.916667         0.946429        0.037718   \n",
      "14            1.000000           0.944444         0.973214        0.022439   \n",
      "15            0.945946           0.916667         0.955357        0.034705   \n",
      "16            0.972973           0.944444         0.946429        0.020589   \n",
      "17            1.000000           0.916667         0.964286        0.034432   \n",
      "18            0.945946           0.916667         0.955357        0.034705   \n",
      "19            0.972973           0.972222         0.973214        0.000890   \n",
      "20            1.000000           0.916667         0.955357        0.033984   \n",
      "21            0.945946           0.916667         0.955357        0.034705   \n",
      "22            1.000000           0.916667         0.955357        0.033984   \n",
      "23            1.000000           0.916667         0.955357        0.033984   \n",
      "24            0.945946           0.916667         0.955357        0.034705   \n",
      "25            1.000000           0.972222         0.982143        0.012573   \n",
      "26            1.000000           0.944444         0.973214        0.022439   \n",
      "27            0.945946           0.916667         0.955357        0.034705   \n",
      "28            1.000000           0.916667         0.937500        0.044597   \n",
      "29            1.000000           0.944444         0.973214        0.022439   \n",
      "..                 ...                ...              ...             ...   \n",
      "510           1.000000           0.944444         0.964286        0.025146   \n",
      "511           1.000000           0.916667         0.955357        0.033984   \n",
      "512           0.972973           0.916667         0.964286        0.034611   \n",
      "513           1.000000           0.944444         0.964286        0.025146   \n",
      "514           0.972973           0.861111         0.928571        0.047491   \n",
      "515           0.945946           0.916667         0.946429        0.023589   \n",
      "516           1.000000           0.888889         0.928571        0.050291   \n",
      "517           0.891892           0.916667         0.919643        0.023487   \n",
      "518           0.945946           0.916667         0.946429        0.023589   \n",
      "519           0.972973           0.944444         0.955357        0.012496   \n",
      "520           1.000000           0.972222         0.973214        0.021126   \n",
      "521           0.945946           0.916667         0.955357        0.034705   \n",
      "522           0.945946           0.916667         0.928571        0.012482   \n",
      "523           1.000000           0.944444         0.964286        0.025146   \n",
      "524           0.945946           0.916667         0.955357        0.034705   \n",
      "525           0.972973           0.944444         0.964286        0.013668   \n",
      "526           1.000000           0.944444         0.964286        0.025146   \n",
      "527           0.945946           0.916667         0.955357        0.034705   \n",
      "528           0.972973           0.916667         0.964286        0.034611   \n",
      "529           1.000000           0.944444         0.973214        0.022439   \n",
      "530           0.945946           0.916667         0.955357        0.034705   \n",
      "531           1.000000           0.972222         0.973214        0.021126   \n",
      "532           1.000000           0.972222         0.973214        0.021126   \n",
      "533           0.972973           0.916667         0.928571        0.032162   \n",
      "534           1.000000           0.944444         0.955357        0.032550   \n",
      "535           1.000000           0.916667         0.955357        0.033984   \n",
      "536           0.945946           0.916667         0.955357        0.034705   \n",
      "537           1.000000           0.916667         0.964286        0.034432   \n",
      "538           1.000000           0.916667         0.955357        0.033984   \n",
      "539           0.972973           0.916667         0.964286        0.034611   \n",
      "\n",
      "     rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                193            0.972603            0.973333   \n",
      "1                193            0.945205            0.853333   \n",
      "2                 20            0.986301            0.973333   \n",
      "3                193            0.972603            0.973333   \n",
      "4                342            0.917808            0.800000   \n",
      "5                106            0.986301            0.960000   \n",
      "6                193            0.972603            0.973333   \n",
      "7                462            0.958904            0.866667   \n",
      "8                300            0.986301            0.973333   \n",
      "9                193            0.972603            0.973333   \n",
      "10               427            0.904110            0.880000   \n",
      "11               106            0.986301            0.960000   \n",
      "12               193            0.972603            0.973333   \n",
      "13               300            0.931507            0.906667   \n",
      "14                20            0.986301            0.946667   \n",
      "15               193            0.972603            0.973333   \n",
      "16               300            0.972603            0.946667   \n",
      "17               106            0.986301            0.973333   \n",
      "18               193            0.972603            0.973333   \n",
      "19                20            0.972603            0.933333   \n",
      "20               193            0.986301            0.973333   \n",
      "21               193            0.972603            0.973333   \n",
      "22               193            0.986301            0.960000   \n",
      "23               193            0.986301            0.973333   \n",
      "24               193            0.972603            0.973333   \n",
      "25                 4            0.986301            0.973333   \n",
      "26                20            0.986301            0.973333   \n",
      "27               193            0.972603            0.973333   \n",
      "28               342            0.835616            0.960000   \n",
      "29                20            0.972603            0.973333   \n",
      "..               ...                 ...                 ...   \n",
      "510              106            1.000000            0.973333   \n",
      "511              193            0.986301            0.960000   \n",
      "512              106            0.972603            0.973333   \n",
      "513              106            0.986301            0.973333   \n",
      "514              378            0.945205            0.960000   \n",
      "515              300            0.972603            0.973333   \n",
      "516              378            0.986301            0.986667   \n",
      "517              427            0.972603            0.800000   \n",
      "518              300            0.972603            0.973333   \n",
      "519              193            0.972603            0.973333   \n",
      "520               20            0.958904            0.973333   \n",
      "521              193            0.972603            0.973333   \n",
      "522              378            0.972603            0.973333   \n",
      "523              106            0.986301            0.960000   \n",
      "524              193            0.972603            0.973333   \n",
      "525              106            0.986301            0.986667   \n",
      "526              106            0.986301            0.960000   \n",
      "527              193            0.972603            0.973333   \n",
      "528              106            0.972603            0.986667   \n",
      "529               20            0.986301            0.973333   \n",
      "530              193            0.972603            0.973333   \n",
      "531               20            0.986301            0.986667   \n",
      "532               20            0.986301            0.973333   \n",
      "533              378            1.000000            0.973333   \n",
      "534              193            0.986301            0.973333   \n",
      "535              193            0.986301            0.973333   \n",
      "536              193            0.972603            0.973333   \n",
      "537              106            0.986301            0.973333   \n",
      "538              193            0.986301            0.973333   \n",
      "539              106            0.972603            0.973333   \n",
      "\n",
      "     split2_train_score  mean_train_score  std_train_score  \n",
      "0              1.000000          0.981979         0.012746  \n",
      "1              0.960526          0.919688         0.047335  \n",
      "2              0.973684          0.977773         0.006032  \n",
      "3              1.000000          0.981979         0.012746  \n",
      "4              0.960526          0.892778         0.067883  \n",
      "5              1.000000          0.982100         0.016598  \n",
      "6              1.000000          0.981979         0.012746  \n",
      "7              0.855263          0.893611         0.046403  \n",
      "8              1.000000          0.986545         0.010888  \n",
      "9              1.000000          0.981979         0.012746  \n",
      "10             0.973684          0.919265         0.039719  \n",
      "11             0.986842          0.977714         0.012528  \n",
      "12             1.000000          0.981979         0.012746  \n",
      "13             0.947368          0.928514         0.016751  \n",
      "14             1.000000          0.977656         0.022615  \n",
      "15             1.000000          0.981979         0.012746  \n",
      "16             0.986842          0.968704         0.016632  \n",
      "17             0.986842          0.982159         0.006245  \n",
      "18             1.000000          0.981979         0.012746  \n",
      "19             0.986842          0.964259         0.022628  \n",
      "20             1.000000          0.986545         0.010888  \n",
      "21             1.000000          0.981979         0.012746  \n",
      "22             0.986842          0.977714         0.012528  \n",
      "23             1.000000          0.986545         0.010888  \n",
      "24             1.000000          0.981979         0.012746  \n",
      "25             0.986842          0.982159         0.006245  \n",
      "26             1.000000          0.986545         0.010888  \n",
      "27             1.000000          0.981979         0.012746  \n",
      "28             0.934211          0.909942         0.053601  \n",
      "29             1.000000          0.981979         0.012746  \n",
      "..                  ...               ...              ...  \n",
      "510            1.000000          0.991111         0.012571  \n",
      "511            0.986842          0.977714         0.012528  \n",
      "512            1.000000          0.981979         0.012746  \n",
      "513            1.000000          0.986545         0.010888  \n",
      "514            0.921053          0.942086         0.016052  \n",
      "515            1.000000          0.981979         0.012746  \n",
      "516            1.000000          0.990989         0.006373  \n",
      "517            0.960526          0.911043         0.078674  \n",
      "518            1.000000          0.981979         0.012746  \n",
      "519            1.000000          0.981979         0.012746  \n",
      "520            0.960526          0.964255         0.006454  \n",
      "521            1.000000          0.981979         0.012746  \n",
      "522            1.000000          0.981979         0.012746  \n",
      "523            0.986842          0.977714         0.012528  \n",
      "524            1.000000          0.981979         0.012746  \n",
      "525            1.000000          0.990989         0.006373  \n",
      "526            0.960526          0.968943         0.012276  \n",
      "527            1.000000          0.981979         0.012746  \n",
      "528            1.000000          0.986423         0.011186  \n",
      "529            0.986842          0.982159         0.006245  \n",
      "530            1.000000          0.981979         0.012746  \n",
      "531            1.000000          0.990989         0.006373  \n",
      "532            0.986842          0.982159         0.006245  \n",
      "533            1.000000          0.991111         0.012571  \n",
      "534            1.000000          0.986545         0.010888  \n",
      "535            0.986842          0.982159         0.006245  \n",
      "536            1.000000          0.981979         0.012746  \n",
      "537            1.000000          0.986545         0.010888  \n",
      "538            1.000000          0.986545         0.010888  \n",
      "539            1.000000          0.981979         0.012746  \n",
      "\n",
      "[540 rows x 20 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(grid.cv_results_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'identity',\n",
       " 'hidden_layer_sizes': (10, 5),\n",
       " 'momentum': 0.7,\n",
       " 'solver': 'adam'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  0 13]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        13\n",
      "Iris-versicolor       1.00      0.92      0.96        12\n",
      " Iris-virginica       0.93      1.00      0.96        13\n",
      "\n",
      "      micro avg       0.97      0.97      0.97        38\n",
      "      macro avg       0.98      0.97      0.97        38\n",
      "   weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1400) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "classificator = MLPClassifier(tol=0.0000001, max_iter= 1400, activation='identity', hidden_layer_sizes=(10, 5), momentum = 0.7)\n",
    "classificator.fit(trainX, trainY)\n",
    "predict = classificator.predict(testX)\n",
    "print(confusion_matrix(testY, predict))\n",
    "print(classification_report(testY, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(iris.drop(['Species', 'SepalWidthCm', 'SepalLengthCm'], axis =1), iris.Species, test_size= 0.25, \n",
    "                                                stratify = iris['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0 13]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        12\n",
      "Iris-versicolor       1.00      0.92      0.96        13\n",
      " Iris-virginica       0.93      1.00      0.96        13\n",
      "\n",
      "      micro avg       0.97      0.97      0.97        38\n",
      "      macro avg       0.98      0.97      0.97        38\n",
      "   weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1400) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "classificator = MLPClassifier(tol=0.0000001, max_iter= 1400, activation='identity', hidden_layer_sizes=(10, 5), momentum = 0.7)\n",
    "classificator.fit(trainX, trainY)\n",
    "predict = classificator.predict(testX)\n",
    "print(confusion_matrix(testY, predict))\n",
    "print(classification_report(testY, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.34045312, -0.67436026, -0.68022079,  0.67872878, -0.16393741,\n",
       "         -0.64526665,  0.51581791, -0.02150414, -0.05518743, -0.67269794],\n",
       "        [-0.28040489, -0.470568  ,  0.03959476, -0.06537006,  0.11414749,\n",
       "          0.54178114,  0.49981833, -1.07580538,  0.11384105, -0.54900175]]),\n",
       " array([[ 0.41025945, -0.34880281,  0.40089914,  0.35132721, -0.4703382 ],\n",
       "        [-0.12262787,  0.04355199,  0.42244533, -0.47972606,  0.10202895],\n",
       "        [ 0.69315793,  0.57004735,  0.20733787, -0.49442033,  0.18556945],\n",
       "        [ 0.01959815,  0.22898907,  0.33150027,  0.74411859,  0.20875503],\n",
       "        [-0.59037982, -0.15701408, -0.29638293,  0.63819829,  0.06699763],\n",
       "        [-0.1842747 , -0.57111963,  0.13577806,  0.53365539,  0.44367411],\n",
       "        [ 0.42785727,  0.38717987, -0.36365111, -0.17843346, -0.03079344],\n",
       "        [ 0.59292874,  0.37979628, -0.1943452 , -0.66483891, -0.76052049],\n",
       "        [ 0.50052925,  0.28654333,  0.84681926, -0.98133463, -0.54455789],\n",
       "        [ 0.12504051, -0.12616333,  0.35237443, -1.08165994, -0.03927922]]),\n",
       " array([[ 0.56615372, -0.36019892, -0.37633657],\n",
       "        [ 0.14528072,  0.86209734, -0.14152123],\n",
       "        [ 0.71038178,  0.28751785, -1.07306123],\n",
       "        [-1.34369799,  0.09493403,  1.20640898],\n",
       "        [ 0.59215756, -0.8202894 ,  0.64912616]])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificator.coefs_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
