{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv('Iris.csv')\n",
    "iris.drop(['Id'], axis = 1, inplace = True)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(iris.drop(['Species'], axis =1), iris.Species, test_size= 0.25, \n",
    "                                                stratify = iris['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentun = lambda l : list(np.array(l) / 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "momentun([10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_test = {\n",
    "    'hidden_layer_sizes':[(10,), (10,5), (20,), (20, 10), (40, 20, 10)],\n",
    "    'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver':['lbfgs', 'sgd', 'adam'],\n",
    "    'momentum': momentun(list(range(10, 100, 10)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificator = MLPClassifier(tol=0.0000001, max_iter= 1400)\n",
    "grid = GridSearchCV(classificator, parameters_test, scoring= 'accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1400) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1400, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=1e-07,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': [(10,), (10, 5), (20,), (20, 10), (40, 20, 10)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'momentum': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0         0.185161      0.078050         0.001330    4.701903e-04   \n",
      "1         0.506961      0.004083         0.001835    6.283727e-04   \n",
      "2         0.525304      0.004785         0.001663    4.697407e-04   \n",
      "3         0.164004      0.072446         0.001507    4.176724e-04   \n",
      "4         0.509406      0.004192         0.001330    4.700217e-04   \n",
      "5         0.545387      0.020115         0.001662    4.699657e-04   \n",
      "6         0.154262      0.046049         0.000998    1.946680e-07   \n",
      "7         0.517879      0.006217         0.001662    4.701342e-04   \n",
      "8         0.545655      0.002503         0.001662    4.700779e-04   \n",
      "9         0.159574      0.065837         0.001995    1.123916e-07   \n",
      "10        0.518402      0.009462         0.001330    4.700779e-04   \n",
      "11        0.553879      0.008842         0.001015    2.461684e-05   \n",
      "12        0.189825      0.120756         0.000998    2.973602e-07   \n",
      "13        0.500835      0.006781         0.000997    1.123916e-07   \n",
      "14        0.536412      0.001028         0.001330    4.697970e-04   \n",
      "15        0.193488      0.073334         0.001662    4.701340e-04   \n",
      "16        0.510656      0.003333         0.000998    2.973602e-07   \n",
      "17        0.531454      0.002488         0.001330    4.700217e-04   \n",
      "18        0.172380      0.121736         0.001330    4.699657e-04   \n",
      "19        0.516664      0.014161         0.000997    2.247832e-07   \n",
      "20        0.560709      0.014574         0.000997    2.247832e-07   \n",
      "21        0.104737      0.051645         0.001330    4.701340e-04   \n",
      "22        0.519305      0.010810         0.001662    4.703589e-04   \n",
      "23        0.558195      0.017781         0.001330    4.701903e-04   \n",
      "24        0.106218      0.048634         0.001330    4.699093e-04   \n",
      "25        0.341763      0.231085         0.001330    4.698531e-04   \n",
      "26        0.540080      0.004072         0.000997    1.123916e-07   \n",
      "27        0.069301      0.025907         0.001662    9.402119e-04   \n",
      "28        0.593936      0.009772         0.000998    2.247832e-07   \n",
      "29        0.644968      0.007332         0.001662    4.703588e-04   \n",
      "..             ...           ...              ...             ...   \n",
      "510       0.104889      0.007640         0.001662    4.699093e-04   \n",
      "511       0.718645      0.027830         0.001995    2.973602e-07   \n",
      "512       0.812884      0.039045         0.000997    1.946680e-07   \n",
      "513       0.064169      0.050865         0.001330    4.701340e-04   \n",
      "514       0.884529      0.008081         0.000997    3.893359e-07   \n",
      "515       0.925922      0.104329         0.001663    4.703026e-04   \n",
      "516       0.069480      0.042644         0.001662    4.703026e-04   \n",
      "517       0.946184      0.048255         0.001330    4.699655e-04   \n",
      "518       1.016004      0.051761         0.000997    5.150430e-07   \n",
      "519       0.109048      0.034798         0.001662    4.699655e-04   \n",
      "520       0.906461      0.007566         0.001662    4.700217e-04   \n",
      "521       1.019025      0.014229         0.000997    1.946680e-07   \n",
      "522       0.113200      0.034814         0.001662    4.700217e-04   \n",
      "523       0.898169      0.004534         0.001663    4.703588e-04   \n",
      "524       0.934072      0.079970         0.001330    4.701903e-04   \n",
      "525       0.124199      0.067850         0.001330    4.699655e-04   \n",
      "526       0.895644      0.002154         0.001330    4.701341e-04   \n",
      "527       0.759504      0.167825         0.001329    4.703026e-04   \n",
      "528       0.224909      0.142363         0.001330    4.699093e-04   \n",
      "529       0.897815      0.002049         0.001662    4.703589e-04   \n",
      "530       0.986767      0.008768         0.001330    4.701903e-04   \n",
      "531       0.084448      0.047481         0.001995    2.973602e-07   \n",
      "532       0.912345      0.027280         0.000997    2.973602e-07   \n",
      "533       0.939443      0.074838         0.000997    1.123916e-07   \n",
      "534       0.099102      0.018347         0.001662    4.706401e-04   \n",
      "535       0.898509      0.008167         0.001662    4.706960e-04   \n",
      "536       0.971155      0.007566         0.000997    1.123916e-07   \n",
      "537       0.132814      0.009343         0.001662    4.699655e-04   \n",
      "538       0.831654      0.014345         0.000997    2.247832e-07   \n",
      "539       0.784772      0.081682         0.000997    1.123916e-07   \n",
      "\n",
      "    param_activation param_hidden_layer_sizes param_momentum param_solver  \\\n",
      "0           identity                    (10,)            0.1        lbfgs   \n",
      "1           identity                    (10,)            0.1          sgd   \n",
      "2           identity                    (10,)            0.1         adam   \n",
      "3           identity                    (10,)            0.2        lbfgs   \n",
      "4           identity                    (10,)            0.2          sgd   \n",
      "5           identity                    (10,)            0.2         adam   \n",
      "6           identity                    (10,)            0.3        lbfgs   \n",
      "7           identity                    (10,)            0.3          sgd   \n",
      "8           identity                    (10,)            0.3         adam   \n",
      "9           identity                    (10,)            0.4        lbfgs   \n",
      "10          identity                    (10,)            0.4          sgd   \n",
      "11          identity                    (10,)            0.4         adam   \n",
      "12          identity                    (10,)            0.5        lbfgs   \n",
      "13          identity                    (10,)            0.5          sgd   \n",
      "14          identity                    (10,)            0.5         adam   \n",
      "15          identity                    (10,)            0.6        lbfgs   \n",
      "16          identity                    (10,)            0.6          sgd   \n",
      "17          identity                    (10,)            0.6         adam   \n",
      "18          identity                    (10,)            0.7        lbfgs   \n",
      "19          identity                    (10,)            0.7          sgd   \n",
      "20          identity                    (10,)            0.7         adam   \n",
      "21          identity                    (10,)            0.8        lbfgs   \n",
      "22          identity                    (10,)            0.8          sgd   \n",
      "23          identity                    (10,)            0.8         adam   \n",
      "24          identity                    (10,)            0.9        lbfgs   \n",
      "25          identity                    (10,)            0.9          sgd   \n",
      "26          identity                    (10,)            0.9         adam   \n",
      "27          identity                  (10, 5)            0.1        lbfgs   \n",
      "28          identity                  (10, 5)            0.1          sgd   \n",
      "29          identity                  (10, 5)            0.1         adam   \n",
      "..               ...                      ...            ...          ...   \n",
      "510             relu                 (20, 10)            0.9        lbfgs   \n",
      "511             relu                 (20, 10)            0.9          sgd   \n",
      "512             relu                 (20, 10)            0.9         adam   \n",
      "513             relu             (40, 20, 10)            0.1        lbfgs   \n",
      "514             relu             (40, 20, 10)            0.1          sgd   \n",
      "515             relu             (40, 20, 10)            0.1         adam   \n",
      "516             relu             (40, 20, 10)            0.2        lbfgs   \n",
      "517             relu             (40, 20, 10)            0.2          sgd   \n",
      "518             relu             (40, 20, 10)            0.2         adam   \n",
      "519             relu             (40, 20, 10)            0.3        lbfgs   \n",
      "520             relu             (40, 20, 10)            0.3          sgd   \n",
      "521             relu             (40, 20, 10)            0.3         adam   \n",
      "522             relu             (40, 20, 10)            0.4        lbfgs   \n",
      "523             relu             (40, 20, 10)            0.4          sgd   \n",
      "524             relu             (40, 20, 10)            0.4         adam   \n",
      "525             relu             (40, 20, 10)            0.5        lbfgs   \n",
      "526             relu             (40, 20, 10)            0.5          sgd   \n",
      "527             relu             (40, 20, 10)            0.5         adam   \n",
      "528             relu             (40, 20, 10)            0.6        lbfgs   \n",
      "529             relu             (40, 20, 10)            0.6          sgd   \n",
      "530             relu             (40, 20, 10)            0.6         adam   \n",
      "531             relu             (40, 20, 10)            0.7        lbfgs   \n",
      "532             relu             (40, 20, 10)            0.7          sgd   \n",
      "533             relu             (40, 20, 10)            0.7         adam   \n",
      "534             relu             (40, 20, 10)            0.8        lbfgs   \n",
      "535             relu             (40, 20, 10)            0.8          sgd   \n",
      "536             relu             (40, 20, 10)            0.8         adam   \n",
      "537             relu             (40, 20, 10)            0.9        lbfgs   \n",
      "538             relu             (40, 20, 10)            0.9          sgd   \n",
      "539             relu             (40, 20, 10)            0.9         adam   \n",
      "\n",
      "                                                params  split0_test_score  \\\n",
      "0    {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "1    {'activation': 'identity', 'hidden_layer_sizes...           0.897436   \n",
      "2    {'activation': 'identity', 'hidden_layer_sizes...           0.948718   \n",
      "3    {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "4    {'activation': 'identity', 'hidden_layer_sizes...           0.871795   \n",
      "5    {'activation': 'identity', 'hidden_layer_sizes...           0.948718   \n",
      "6    {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "7    {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "8    {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "9    {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "10   {'activation': 'identity', 'hidden_layer_sizes...           0.820513   \n",
      "11   {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "12   {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "13   {'activation': 'identity', 'hidden_layer_sizes...           0.871795   \n",
      "14   {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "15   {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "16   {'activation': 'identity', 'hidden_layer_sizes...           0.897436   \n",
      "17   {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "18   {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "19   {'activation': 'identity', 'hidden_layer_sizes...           0.897436   \n",
      "20   {'activation': 'identity', 'hidden_layer_sizes...           0.948718   \n",
      "21   {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "22   {'activation': 'identity', 'hidden_layer_sizes...           0.897436   \n",
      "23   {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "24   {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "25   {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "26   {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "27   {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "28   {'activation': 'identity', 'hidden_layer_sizes...           0.846154   \n",
      "29   {'activation': 'identity', 'hidden_layer_sizes...           0.923077   \n",
      "..                                                 ...                ...   \n",
      "510  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "511  {'activation': 'relu', 'hidden_layer_sizes': (...           0.897436   \n",
      "512  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "513  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
      "514  {'activation': 'relu', 'hidden_layer_sizes': (...           0.692308   \n",
      "515  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "516  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "517  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "518  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "519  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "520  {'activation': 'relu', 'hidden_layer_sizes': (...           0.897436   \n",
      "521  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "522  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "523  {'activation': 'relu', 'hidden_layer_sizes': (...           0.871795   \n",
      "524  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "525  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "526  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "527  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "528  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "529  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "530  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "531  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "532  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "533  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "534  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "535  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "536  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "537  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "538  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "539  {'activation': 'relu', 'hidden_layer_sizes': (...           0.923077   \n",
      "\n",
      "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
      "0             0.945946           0.944444         0.937500        0.010560   \n",
      "1             0.972973           0.777778         0.883929        0.079402   \n",
      "2             0.945946           1.000000         0.964286        0.024607   \n",
      "3             0.891892           0.972222         0.928571        0.032671   \n",
      "4             0.945946           0.861111         0.892857        0.037543   \n",
      "5             1.000000           1.000000         0.982143        0.024431   \n",
      "6             0.945946           0.972222         0.946429        0.020095   \n",
      "7             0.972973           1.000000         0.964286        0.032035   \n",
      "8             0.945946           1.000000         0.955357        0.032136   \n",
      "9             0.945946           0.972222         0.946429        0.020095   \n",
      "10            0.945946           1.000000         0.919643        0.075670   \n",
      "11            0.972973           1.000000         0.964286        0.032035   \n",
      "12            0.945946           0.972222         0.946429        0.020095   \n",
      "13            0.918919           1.000000         0.928571        0.052851   \n",
      "14            0.972973           1.000000         0.964286        0.032035   \n",
      "15            0.945946           0.972222         0.946429        0.020095   \n",
      "16            0.972973           1.000000         0.955357        0.043719   \n",
      "17            0.972973           1.000000         0.964286        0.032035   \n",
      "18            0.945946           0.972222         0.946429        0.020095   \n",
      "19            0.972973           1.000000         0.955357        0.043719   \n",
      "20            0.972973           1.000000         0.973214        0.020966   \n",
      "21            0.945946           0.972222         0.946429        0.020095   \n",
      "22            0.945946           1.000000         0.946429        0.041933   \n",
      "23            0.945946           1.000000         0.955357        0.032136   \n",
      "24            0.945946           0.972222         0.946429        0.020095   \n",
      "25            0.351351           1.000000         0.758929        0.287995   \n",
      "26            0.972973           1.000000         0.964286        0.032035   \n",
      "27            0.945946           0.972222         0.946429        0.020095   \n",
      "28            0.675676           1.000000         0.839286        0.131003   \n",
      "29            0.945946           1.000000         0.955357        0.032136   \n",
      "..                 ...                ...              ...             ...   \n",
      "510           0.945946           0.972222         0.946429        0.020095   \n",
      "511           0.945946           1.000000         0.946429        0.041933   \n",
      "512           0.972973           1.000000         0.964286        0.032035   \n",
      "513           0.945946           1.000000         0.750000        0.305331   \n",
      "514           0.972973           0.861111         0.839286        0.116532   \n",
      "515           0.945946           1.000000         0.955357        0.032136   \n",
      "516           0.945946           0.944444         0.937500        0.010560   \n",
      "517           1.000000           1.000000         0.973214        0.036646   \n",
      "518           0.972973           1.000000         0.964286        0.032035   \n",
      "519           0.918919           0.972222         0.937500        0.023959   \n",
      "520           0.918919           1.000000         0.937500        0.043915   \n",
      "521           0.972973           0.972222         0.955357        0.023596   \n",
      "522           0.945946           0.972222         0.946429        0.020095   \n",
      "523           0.945946           0.972222         0.928571        0.042833   \n",
      "524           0.945946           1.000000         0.955357        0.032136   \n",
      "525           0.972973           1.000000         0.964286        0.032035   \n",
      "526           1.000000           1.000000         0.973214        0.036646   \n",
      "527           0.972973           1.000000         0.964286        0.032035   \n",
      "528           0.918919           1.000000         0.946429        0.036910   \n",
      "529           1.000000           1.000000         0.973214        0.036646   \n",
      "530           0.945946           1.000000         0.955357        0.032136   \n",
      "531           0.918919           1.000000         0.946429        0.036910   \n",
      "532           1.000000           1.000000         0.973214        0.036646   \n",
      "533           0.972973           1.000000         0.964286        0.032035   \n",
      "534           0.945946           1.000000         0.955357        0.032136   \n",
      "535           0.945946           1.000000         0.955357        0.032136   \n",
      "536           0.945946           1.000000         0.955357        0.032136   \n",
      "537           0.945946           0.972222         0.946429        0.020095   \n",
      "538           0.918919           1.000000         0.946429        0.036910   \n",
      "539           0.972973           1.000000         0.964286        0.032035   \n",
      "\n",
      "     rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                404            1.000000            1.000000   \n",
      "1                456            0.945205            0.933333   \n",
      "2                 48            0.986301            0.986667   \n",
      "3                433            1.000000            1.000000   \n",
      "4                454            0.945205            0.973333   \n",
      "5                  1            0.986301            0.986667   \n",
      "6                267            1.000000            1.000000   \n",
      "7                 48            0.958904            0.960000   \n",
      "8                132            0.986301            0.973333   \n",
      "9                267            1.000000            1.000000   \n",
      "10               440            0.863014            0.933333   \n",
      "11                48            0.986301            0.960000   \n",
      "12               267            1.000000            1.000000   \n",
      "13               433            0.972603            0.946667   \n",
      "14                48            0.986301            0.986667   \n",
      "15               267            1.000000            1.000000   \n",
      "16               132            0.986301            0.960000   \n",
      "17                48            0.986301            0.986667   \n",
      "18               267            1.000000            1.000000   \n",
      "19               132            0.986301            0.973333   \n",
      "20                 5            0.986301            0.986667   \n",
      "21               267            1.000000            1.000000   \n",
      "22               267            0.986301            0.960000   \n",
      "23               132            1.000000            0.986667   \n",
      "24               267            1.000000            1.000000   \n",
      "25               486            0.986301            0.360000   \n",
      "26                48            0.986301            0.986667   \n",
      "27               267            1.000000            1.000000   \n",
      "28               469            0.945205            0.666667   \n",
      "29               132            1.000000            0.986667   \n",
      "..               ...                 ...                 ...   \n",
      "510              267            1.000000            0.986667   \n",
      "511              267            0.986301            0.973333   \n",
      "512               48            1.000000            0.986667   \n",
      "513              489            0.342466            1.000000   \n",
      "514              469            0.726027            0.973333   \n",
      "515              132            1.000000            0.986667   \n",
      "516              404            1.000000            1.000000   \n",
      "517                5            0.986301            0.960000   \n",
      "518               48            1.000000            0.986667   \n",
      "519              404            1.000000            0.986667   \n",
      "520              404            0.986301            0.920000   \n",
      "521              132            1.000000            0.986667   \n",
      "522              267            1.000000            0.986667   \n",
      "523              433            0.986301            0.960000   \n",
      "524              132            1.000000            0.986667   \n",
      "525               48            1.000000            0.986667   \n",
      "526                5            0.972603            0.960000   \n",
      "527               48            1.000000            1.000000   \n",
      "528              267            1.000000            1.000000   \n",
      "529                5            0.986301            0.973333   \n",
      "530              132            1.000000            0.986667   \n",
      "531              267            1.000000            1.000000   \n",
      "532                5            0.986301            0.986667   \n",
      "533               48            1.000000            0.986667   \n",
      "534              132            1.000000            1.000000   \n",
      "535              132            0.986301            0.986667   \n",
      "536              132            1.000000            1.000000   \n",
      "537              267            1.000000            1.000000   \n",
      "538              267            1.000000            0.986667   \n",
      "539               48            1.000000            0.986667   \n",
      "\n",
      "     split2_train_score  mean_train_score  std_train_score  \n",
      "0              1.000000          1.000000         0.000000  \n",
      "1              0.776316          0.884952         0.076970  \n",
      "2              0.947368          0.973445         0.018440  \n",
      "3              1.000000          1.000000         0.000000  \n",
      "4              0.881579          0.933373         0.038382  \n",
      "5              0.960526          0.977831         0.012237  \n",
      "6              1.000000          1.000000         0.000000  \n",
      "7              0.921053          0.946652         0.018107  \n",
      "8              0.986842          0.982159         0.006245  \n",
      "9              1.000000          1.000000         0.000000  \n",
      "10             0.947368          0.914572         0.036905  \n",
      "11             0.960526          0.968943         0.012276  \n",
      "12             1.000000          1.000000         0.000000  \n",
      "13             0.921053          0.946774         0.021045  \n",
      "14             0.960526          0.977831         0.012237  \n",
      "15             1.000000          1.000000         0.000000  \n",
      "16             0.960526          0.968943         0.012276  \n",
      "17             0.960526          0.977831         0.012237  \n",
      "18             1.000000          1.000000         0.000000  \n",
      "19             0.947368          0.969001         0.016187  \n",
      "20             0.960526          0.977831         0.012237  \n",
      "21             1.000000          1.000000         0.000000  \n",
      "22             0.960526          0.968943         0.012276  \n",
      "23             0.960526          0.982398         0.016395  \n",
      "24             1.000000          1.000000         0.000000  \n",
      "25             0.973684          0.773329         0.292313  \n",
      "26             0.973684          0.982217         0.006036  \n",
      "27             1.000000          1.000000         0.000000  \n",
      "28             0.947368          0.853080         0.131817  \n",
      "29             0.986842          0.991170         0.006244  \n",
      "..                  ...               ...              ...  \n",
      "510            1.000000          0.995556         0.006285  \n",
      "511            0.973684          0.977773         0.006032  \n",
      "512            0.986842          0.991170         0.006244  \n",
      "513            0.973684          0.772050         0.303952  \n",
      "514            0.828947          0.842769         0.101434  \n",
      "515            0.986842          0.991170         0.006244  \n",
      "516            0.934211          0.978070         0.031013  \n",
      "517            0.947368          0.964557         0.016218  \n",
      "518            1.000000          0.995556         0.006285  \n",
      "519            1.000000          0.995556         0.006285  \n",
      "520            0.921053          0.942451         0.031010  \n",
      "521            0.986842          0.991170         0.006244  \n",
      "522            0.986842          0.991170         0.006244  \n",
      "523            0.934211          0.960171         0.021266  \n",
      "524            0.986842          0.991170         0.006244  \n",
      "525            0.973684          0.986784         0.010744  \n",
      "526            0.960526          0.964376         0.005821  \n",
      "527            0.986842          0.995614         0.006203  \n",
      "528            0.986842          0.995614         0.006203  \n",
      "529            0.934211          0.964615         0.022142  \n",
      "530            0.986842          0.991170         0.006244  \n",
      "531            0.973684          0.991228         0.012405  \n",
      "532            0.973684          0.982217         0.006036  \n",
      "533            0.986842          0.991170         0.006244  \n",
      "534            0.973684          0.991228         0.012405  \n",
      "535            0.986842          0.986603         0.000225  \n",
      "536            0.986842          0.995614         0.006203  \n",
      "537            1.000000          1.000000         0.000000  \n",
      "538            0.973684          0.986784         0.010744  \n",
      "539            0.986842          0.991170         0.006244  \n",
      "\n",
      "[540 rows x 20 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(grid.cv_results_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'identity',\n",
       " 'hidden_layer_sizes': (10,),\n",
       " 'momentum': 0.2,\n",
       " 'solver': 'adam'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  1 11]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        13\n",
      "Iris-versicolor       0.93      1.00      0.96        13\n",
      " Iris-virginica       1.00      0.92      0.96        12\n",
      "\n",
      "      micro avg       0.97      0.97      0.97        38\n",
      "      macro avg       0.98      0.97      0.97        38\n",
      "   weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1400) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "classificator = MLPClassifier(tol=0.0000001, max_iter= 1400, activation='identity', hidden_layer_sizes=(10, 5), momentum = 0.7)\n",
    "classificator.fit(trainX, trainY)\n",
    "predict = classificator.predict(testX)\n",
    "print(confusion_matrix(testY, predict))\n",
    "print(classification_report(testY, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(iris.drop(['Species', 'SepalWidthCm', 'SepalLengthCm'], axis =1), iris.Species, test_size= 0.25, \n",
    "                                                stratify = iris['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 12]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        13\n",
      "Iris-versicolor       1.00      1.00      1.00        13\n",
      " Iris-virginica       1.00      1.00      1.00        12\n",
      "\n",
      "      micro avg       1.00      1.00      1.00        38\n",
      "      macro avg       1.00      1.00      1.00        38\n",
      "   weighted avg       1.00      1.00      1.00        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1400) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "classificator = MLPClassifier(tol=0.0000001, max_iter= 1400, activation='identity', hidden_layer_sizes=(10, 5), momentum = 0.7)\n",
    "classificator.fit(trainX, trainY)\n",
    "predict = classificator.predict(testX)\n",
    "print(confusion_matrix(testY, predict))\n",
    "print(classification_report(testY, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.28681187, -0.6261724 , -0.02451678,  0.0571237 , -0.23744967,\n",
       "         -0.62494348, -0.7529671 , -0.02278198,  0.49960451, -0.54101324],\n",
       "        [ 0.60657583, -1.004899  , -0.58462274, -0.20201561, -0.71494793,\n",
       "         -0.3734379 , -0.07887031,  0.92958493, -0.86056569,  0.39941591]]),\n",
       " array([[-9.78167398e-01, -3.97408925e-01,  3.17428624e-01,\n",
       "         -3.83901943e-01,  1.45594752e-01],\n",
       "        [ 7.39409721e-01, -1.84441779e-01,  4.72179291e-01,\n",
       "          1.04494132e-03, -1.05846109e+00],\n",
       "        [ 8.62199775e-01,  1.80708672e-01, -3.37342148e-01,\n",
       "         -1.65348820e-01, -5.73048757e-01],\n",
       "        [ 3.13601436e-01,  3.40573190e-01,  7.49212905e-01,\n",
       "          5.95449998e-01, -3.08329023e-01],\n",
       "        [ 6.86432274e-01, -2.81211809e-01,  4.17896419e-01,\n",
       "          5.43343294e-01,  1.49235309e-01],\n",
       "        [-7.14130719e-01,  2.31383622e-01, -3.32480242e-01,\n",
       "          4.52027407e-01,  3.69584903e-01],\n",
       "        [ 4.26454759e-01, -4.17193483e-01,  6.09711090e-01,\n",
       "          3.59340213e-01,  1.47471994e-01],\n",
       "        [-1.26977210e+00,  3.17804686e-01, -7.19774669e-01,\n",
       "         -3.59017113e-01,  2.69209844e-01],\n",
       "        [ 1.18563779e+00, -3.74104373e-01,  1.35957808e-01,\n",
       "          5.69329247e-01,  2.09746939e-01],\n",
       "        [-2.72815545e-01, -1.98780735e-01, -3.16576565e-01,\n",
       "          6.04912577e-01, -5.91234770e-01]]),\n",
       " array([[ 1.11081114,  0.66232453, -0.59351486],\n",
       "        [ 0.34192756, -0.64983584,  0.68196542],\n",
       "        [ 0.97939601,  0.48914714, -1.0512581 ],\n",
       "        [ 1.13081076, -0.28027766,  0.05473114],\n",
       "        [-0.84849927,  0.33313639,  0.46569061]])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificator.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "XC = iris.drop(['Species'], axis = 1) #X completo\n",
    "XP = iris.drop(['SepalLengthCm', 'SepalWidthCm', 'Species'], axis=1) #X Parcial\n",
    "Y = iris['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         0.93333333 0.93333333 1.        ]\n"
     ]
    }
   ],
   "source": [
    "NeuralNetwork = MLPClassifier(tol=0.0000001, max_iter= 21400, activation='identity', hidden_layer_sizes=(10, 5), momentum = 0.7)\n",
    "score = cross_val_score(NeuralNetwork, XC, Y, cv=5)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acuracia da Iris com todos atributos tem:\n",
      "Média: 0.97 e Desvio Padrão de +/-: 0.03\n"
     ]
    }
   ],
   "source": [
    "print('A acuracia da Iris com todos atributos tem:')\n",
    "print('Média: %0.2f e Desvio Padrão de +/-: %0.2f' % (np.mean(score), np.std(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 0.96666667 0.93333333 0.9        1.        ]\n"
     ]
    }
   ],
   "source": [
    "NeuralNetwork = MLPClassifier(tol=0.0000001, max_iter= 21400, activation='identity', hidden_layer_sizes=(10, 5), momentum = 0.7)\n",
    "score = cross_val_score(NeuralNetwork, XP, Y, cv=5)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acuracia da Iris só com atributo da Petalas tem:\n",
      "Média: 0.95 e Desvio Padrão de +/-: 0.03\n"
     ]
    }
   ],
   "source": [
    "print('A acuracia da Iris só com atributo da Petalas tem:')\n",
    "print('Média: %0.2f e Desvio Padrão de +/-: %0.2f' % (np.mean(score), np.std(score)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
