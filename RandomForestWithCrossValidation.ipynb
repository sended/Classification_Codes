{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv('Iris.csv')\n",
    "iris.drop(['Id'], axis = 1, inplace = True)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(iris.drop(['Species'], axis =1), iris.Species, test_size= 0.25, \n",
    "                                                stratify = iris['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_test = {\n",
    "    'n_estimators':[5,10,20,40,100],\n",
    "    'criterion':['gini', 'entropy'],\n",
    "    #'max_features':[int, float, 'sqrt', 'log2', None],\n",
    "    'max_depth':[None, 3, 4, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificator = RandomForestClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator= classificator, param_grid= parameters_test, scoring= 'accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [5, 10, 20, 40, 100], 'criterion': ['gini', 'entropy'], 'max_depth': [None, 3, 4, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0        0.110215  1.801691e-03         0.107673    1.546295e-03   \n",
      "1        0.110894  1.981017e-03         0.111322    2.745291e-03   \n",
      "2        0.114476  2.143500e-03         0.116755    1.417188e-03   \n",
      "3        0.123611  3.672012e-03         0.108560    4.382148e-03   \n",
      "4        0.129314  4.654335e-04         0.104633    3.715728e-06   \n",
      "5        0.106984  1.005765e-03         0.102803    1.670028e-04   \n",
      "6        0.109240  8.440281e-04         0.103194    4.873647e-04   \n",
      "7        0.110185  4.034252e-04         0.110096    5.150804e-03   \n",
      "8        0.115026  4.708648e-04         0.103421    8.084691e-04   \n",
      "9        0.132186  1.629511e-03         0.115151    1.901795e-03   \n",
      "10       0.106085  9.383711e-04         0.111121    4.791951e-04   \n",
      "11       0.108071  9.409988e-04         0.111113    3.081136e-03   \n",
      "12       0.114292  2.861053e-03         0.104648    1.403771e-06   \n",
      "13       0.114651  2.964412e-05         0.112199    5.887262e-03   \n",
      "14       0.132906  1.243137e-03         0.111055    4.628406e-03   \n",
      "15       0.106976  4.691795e-04         0.111058    4.675014e-04   \n",
      "16       0.111115  2.861094e-03         0.103548    4.699657e-04   \n",
      "17       0.116619  9.776919e-03         0.111705    4.000668e-03   \n",
      "18       0.115532  4.814875e-04         0.108630    1.234360e-03   \n",
      "19       0.132935  9.482252e-04         0.114480    1.612966e-05   \n",
      "20       0.105148  1.946680e-07         0.102566    4.971307e-04   \n",
      "21       0.107090  3.158502e-04         0.104952    1.249523e-03   \n",
      "22       0.109188  4.643146e-04         0.105469    4.642514e-04   \n",
      "23       0.114721  8.025023e-04         0.103616    4.653369e-04   \n",
      "24       0.134431  5.022910e-03         0.105657    5.026958e-05   \n",
      "25       0.112277  4.904632e-03         0.103848    2.805074e-04   \n",
      "26       0.106946  4.391065e-04         0.102551    6.855998e-05   \n",
      "27       0.110979  4.741240e-04         0.115692    4.722256e-04   \n",
      "28       0.116452  8.137122e-04         0.103599    7.867412e-07   \n",
      "29       0.130823  6.412172e-04         0.111853    4.009514e-03   \n",
      "30       0.105865  4.718805e-04         0.104230    8.117665e-04   \n",
      "31       0.108586  8.141988e-04         0.102697    1.620935e-06   \n",
      "32       0.108977  4.801371e-06         0.104475    4.675134e-04   \n",
      "33       0.115800  5.038370e-04         0.103032    6.242327e-04   \n",
      "34       0.136027  2.549135e-03         0.103814    3.871462e-04   \n",
      "35       0.107140  1.243965e-03         0.102514    3.114687e-06   \n",
      "36       0.106922  4.945230e-06         0.103078    4.700779e-04   \n",
      "37       0.123961  4.879475e-03         0.103527    4.905105e-04   \n",
      "38       0.116708  8.136152e-04         0.105440    4.699118e-04   \n",
      "39       0.131040  1.433274e-03         0.104323    1.968042e-04   \n",
      "\n",
      "   param_criterion param_max_depth param_n_estimators  \\\n",
      "0             gini            None                  5   \n",
      "1             gini            None                 10   \n",
      "2             gini            None                 20   \n",
      "3             gini            None                 40   \n",
      "4             gini            None                100   \n",
      "5             gini               3                  5   \n",
      "6             gini               3                 10   \n",
      "7             gini               3                 20   \n",
      "8             gini               3                 40   \n",
      "9             gini               3                100   \n",
      "10            gini               4                  5   \n",
      "11            gini               4                 10   \n",
      "12            gini               4                 20   \n",
      "13            gini               4                 40   \n",
      "14            gini               4                100   \n",
      "15            gini              10                  5   \n",
      "16            gini              10                 10   \n",
      "17            gini              10                 20   \n",
      "18            gini              10                 40   \n",
      "19            gini              10                100   \n",
      "20         entropy            None                  5   \n",
      "21         entropy            None                 10   \n",
      "22         entropy            None                 20   \n",
      "23         entropy            None                 40   \n",
      "24         entropy            None                100   \n",
      "25         entropy               3                  5   \n",
      "26         entropy               3                 10   \n",
      "27         entropy               3                 20   \n",
      "28         entropy               3                 40   \n",
      "29         entropy               3                100   \n",
      "30         entropy               4                  5   \n",
      "31         entropy               4                 10   \n",
      "32         entropy               4                 20   \n",
      "33         entropy               4                 40   \n",
      "34         entropy               4                100   \n",
      "35         entropy              10                  5   \n",
      "36         entropy              10                 10   \n",
      "37         entropy              10                 20   \n",
      "38         entropy              10                 40   \n",
      "39         entropy              10                100   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "0   {'criterion': 'gini', 'max_depth': None, 'n_es...           0.923077   \n",
      "1   {'criterion': 'gini', 'max_depth': None, 'n_es...           0.948718   \n",
      "2   {'criterion': 'gini', 'max_depth': None, 'n_es...           1.000000   \n",
      "3   {'criterion': 'gini', 'max_depth': None, 'n_es...           0.974359   \n",
      "4   {'criterion': 'gini', 'max_depth': None, 'n_es...           0.974359   \n",
      "5   {'criterion': 'gini', 'max_depth': 3, 'n_estim...           0.948718   \n",
      "6   {'criterion': 'gini', 'max_depth': 3, 'n_estim...           0.948718   \n",
      "7   {'criterion': 'gini', 'max_depth': 3, 'n_estim...           1.000000   \n",
      "8   {'criterion': 'gini', 'max_depth': 3, 'n_estim...           0.948718   \n",
      "9   {'criterion': 'gini', 'max_depth': 3, 'n_estim...           1.000000   \n",
      "10  {'criterion': 'gini', 'max_depth': 4, 'n_estim...           0.948718   \n",
      "11  {'criterion': 'gini', 'max_depth': 4, 'n_estim...           1.000000   \n",
      "12  {'criterion': 'gini', 'max_depth': 4, 'n_estim...           1.000000   \n",
      "13  {'criterion': 'gini', 'max_depth': 4, 'n_estim...           0.974359   \n",
      "14  {'criterion': 'gini', 'max_depth': 4, 'n_estim...           0.974359   \n",
      "15  {'criterion': 'gini', 'max_depth': 10, 'n_esti...           0.948718   \n",
      "16  {'criterion': 'gini', 'max_depth': 10, 'n_esti...           0.974359   \n",
      "17  {'criterion': 'gini', 'max_depth': 10, 'n_esti...           0.948718   \n",
      "18  {'criterion': 'gini', 'max_depth': 10, 'n_esti...           0.974359   \n",
      "19  {'criterion': 'gini', 'max_depth': 10, 'n_esti...           0.974359   \n",
      "20  {'criterion': 'entropy', 'max_depth': None, 'n...           1.000000   \n",
      "21  {'criterion': 'entropy', 'max_depth': None, 'n...           0.974359   \n",
      "22  {'criterion': 'entropy', 'max_depth': None, 'n...           0.948718   \n",
      "23  {'criterion': 'entropy', 'max_depth': None, 'n...           0.974359   \n",
      "24  {'criterion': 'entropy', 'max_depth': None, 'n...           1.000000   \n",
      "25  {'criterion': 'entropy', 'max_depth': 3, 'n_es...           0.948718   \n",
      "26  {'criterion': 'entropy', 'max_depth': 3, 'n_es...           0.974359   \n",
      "27  {'criterion': 'entropy', 'max_depth': 3, 'n_es...           0.974359   \n",
      "28  {'criterion': 'entropy', 'max_depth': 3, 'n_es...           0.974359   \n",
      "29  {'criterion': 'entropy', 'max_depth': 3, 'n_es...           1.000000   \n",
      "30  {'criterion': 'entropy', 'max_depth': 4, 'n_es...           1.000000   \n",
      "31  {'criterion': 'entropy', 'max_depth': 4, 'n_es...           0.974359   \n",
      "32  {'criterion': 'entropy', 'max_depth': 4, 'n_es...           0.948718   \n",
      "33  {'criterion': 'entropy', 'max_depth': 4, 'n_es...           0.974359   \n",
      "34  {'criterion': 'entropy', 'max_depth': 4, 'n_es...           1.000000   \n",
      "35  {'criterion': 'entropy', 'max_depth': 10, 'n_e...           1.000000   \n",
      "36  {'criterion': 'entropy', 'max_depth': 10, 'n_e...           1.000000   \n",
      "37  {'criterion': 'entropy', 'max_depth': 10, 'n_e...           1.000000   \n",
      "38  {'criterion': 'entropy', 'max_depth': 10, 'n_e...           1.000000   \n",
      "39  {'criterion': 'entropy', 'max_depth': 10, 'n_e...           1.000000   \n",
      "\n",
      "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
      "0            0.972973           0.944444         0.946429        0.020589   \n",
      "1            0.945946           0.944444         0.946429        0.001780   \n",
      "2            0.972973           0.944444         0.973214        0.022713   \n",
      "3            0.972973           0.944444         0.964286        0.013668   \n",
      "4            0.945946           0.944444         0.955357        0.013902   \n",
      "5            0.945946           0.944444         0.946429        0.001780   \n",
      "6            0.945946           0.944444         0.946429        0.001780   \n",
      "7            0.945946           0.944444         0.964286        0.026111   \n",
      "8            0.945946           0.944444         0.946429        0.001780   \n",
      "9            0.945946           0.944444         0.964286        0.026111   \n",
      "10           0.945946           0.944444         0.946429        0.001780   \n",
      "11           0.945946           0.944444         0.964286        0.026111   \n",
      "12           0.972973           0.944444         0.973214        0.022713   \n",
      "13           0.945946           0.944444         0.955357        0.013902   \n",
      "14           0.972973           0.944444         0.964286        0.013668   \n",
      "15           0.864865           0.944444         0.919643        0.038514   \n",
      "16           0.945946           0.944444         0.955357        0.013902   \n",
      "17           0.945946           0.944444         0.946429        0.001780   \n",
      "18           0.972973           0.944444         0.964286        0.013668   \n",
      "19           0.972973           0.944444         0.964286        0.013668   \n",
      "20           0.945946           0.972222         0.973214        0.022266   \n",
      "21           0.945946           0.944444         0.955357        0.013902   \n",
      "22           0.945946           0.944444         0.946429        0.001780   \n",
      "23           0.945946           0.944444         0.955357        0.013902   \n",
      "24           0.945946           0.944444         0.964286        0.026111   \n",
      "25           0.972973           0.944444         0.955357        0.012496   \n",
      "26           0.945946           0.944444         0.955357        0.013902   \n",
      "27           0.945946           0.944444         0.955357        0.013902   \n",
      "28           0.945946           0.944444         0.955357        0.013902   \n",
      "29           0.972973           0.944444         0.973214        0.022713   \n",
      "30           0.945946           0.944444         0.964286        0.026111   \n",
      "31           0.945946           0.944444         0.955357        0.013902   \n",
      "32           0.945946           0.944444         0.946429        0.001780   \n",
      "33           0.945946           0.944444         0.955357        0.013902   \n",
      "34           0.945946           0.944444         0.964286        0.026111   \n",
      "35           0.945946           0.944444         0.964286        0.026111   \n",
      "36           0.945946           0.944444         0.964286        0.026111   \n",
      "37           0.945946           0.944444         0.964286        0.026111   \n",
      "38           0.972973           0.944444         0.973214        0.022713   \n",
      "39           0.945946           0.944444         0.964286        0.026111   \n",
      "\n",
      "    rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                31            0.986301            0.986667   \n",
      "1                31            1.000000            1.000000   \n",
      "2                 1            1.000000            1.000000   \n",
      "3                 6            1.000000            1.000000   \n",
      "4                20            1.000000            1.000000   \n",
      "5                31            0.972603            0.986667   \n",
      "6                31            0.958904            0.986667   \n",
      "7                 6            0.972603            0.986667   \n",
      "8                31            0.958904            1.000000   \n",
      "9                 6            0.986301            0.986667   \n",
      "10               31            1.000000            1.000000   \n",
      "11                6            0.986301            1.000000   \n",
      "12                1            0.986301            1.000000   \n",
      "13               20            0.986301            1.000000   \n",
      "14                6            0.986301            1.000000   \n",
      "15               40            0.986301            1.000000   \n",
      "16               20            1.000000            1.000000   \n",
      "17               31            0.986301            1.000000   \n",
      "18                6            1.000000            1.000000   \n",
      "19                6            1.000000            1.000000   \n",
      "20                1            0.986301            0.986667   \n",
      "21               20            1.000000            1.000000   \n",
      "22               31            1.000000            1.000000   \n",
      "23               20            1.000000            1.000000   \n",
      "24                6            1.000000            1.000000   \n",
      "25               20            0.958904            0.986667   \n",
      "26               20            0.958904            0.986667   \n",
      "27               20            0.972603            0.986667   \n",
      "28               20            0.972603            0.986667   \n",
      "29                1            0.972603            0.986667   \n",
      "30                6            1.000000            1.000000   \n",
      "31               20            0.986301            0.986667   \n",
      "32               31            0.972603            1.000000   \n",
      "33               20            1.000000            1.000000   \n",
      "34                6            0.986301            1.000000   \n",
      "35                6            0.986301            1.000000   \n",
      "36                6            0.986301            0.986667   \n",
      "37                6            1.000000            1.000000   \n",
      "38                1            1.000000            1.000000   \n",
      "39                6            1.000000            1.000000   \n",
      "\n",
      "    split2_train_score  mean_train_score  std_train_score  \n",
      "0             1.000000          0.990989         0.006373  \n",
      "1             1.000000          1.000000         0.000000  \n",
      "2             1.000000          1.000000         0.000000  \n",
      "3             1.000000          1.000000         0.000000  \n",
      "4             1.000000          1.000000         0.000000  \n",
      "5             1.000000          0.986423         0.011186  \n",
      "6             0.986842          0.977471         0.013129  \n",
      "7             1.000000          0.986423         0.011186  \n",
      "8             1.000000          0.986301         0.019373  \n",
      "9             1.000000          0.990989         0.006373  \n",
      "10            0.986842          0.995614         0.006203  \n",
      "11            1.000000          0.995434         0.006458  \n",
      "12            1.000000          0.995434         0.006458  \n",
      "13            1.000000          0.995434         0.006458  \n",
      "14            1.000000          0.995434         0.006458  \n",
      "15            0.986842          0.991048         0.006334  \n",
      "16            1.000000          1.000000         0.000000  \n",
      "17            1.000000          0.995434         0.006458  \n",
      "18            1.000000          1.000000         0.000000  \n",
      "19            1.000000          1.000000         0.000000  \n",
      "20            1.000000          0.990989         0.006373  \n",
      "21            1.000000          1.000000         0.000000  \n",
      "22            1.000000          1.000000         0.000000  \n",
      "23            1.000000          1.000000         0.000000  \n",
      "24            1.000000          1.000000         0.000000  \n",
      "25            1.000000          0.981857         0.017119  \n",
      "26            1.000000          0.981857         0.017119  \n",
      "27            1.000000          0.986423         0.011186  \n",
      "28            1.000000          0.986423         0.011186  \n",
      "29            1.000000          0.986423         0.011186  \n",
      "30            1.000000          1.000000         0.000000  \n",
      "31            1.000000          0.990989         0.006373  \n",
      "32            0.986842          0.986482         0.011188  \n",
      "33            1.000000          1.000000         0.000000  \n",
      "34            1.000000          0.995434         0.006458  \n",
      "35            1.000000          0.995434         0.006458  \n",
      "36            1.000000          0.990989         0.006373  \n",
      "37            1.000000          1.000000         0.000000  \n",
      "38            1.000000          1.000000         0.000000  \n",
      "39            1.000000          1.000000         0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(grid.cv_results_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': None, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificator = RandomForestClassifier(criterion='gini', n_estimators=20, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificator.fit(trainX, trainY)\n",
    "predict = classificator.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  1 11]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        13\n",
      "Iris-versicolor       0.92      0.92      0.92        13\n",
      " Iris-virginica       0.92      0.92      0.92        12\n",
      "\n",
      "      micro avg       0.95      0.95      0.95        38\n",
      "      macro avg       0.95      0.95      0.95        38\n",
      "   weighted avg       0.95      0.95      0.95        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(testY, predict))\n",
    "print(classification_report(testY, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 4 artists>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.barh(iris.columns[:-1], classificator.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(iris.drop(['Species', 'SepalWidthCm', 'SepalLengthCm'], axis =1), iris.Species, test_size= 0.25, \n",
    "                                                stratify = iris['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  0 13]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        13\n",
      "Iris-versicolor       1.00      0.92      0.96        12\n",
      " Iris-virginica       0.93      1.00      0.96        13\n",
      "\n",
      "      micro avg       0.97      0.97      0.97        38\n",
      "      macro avg       0.98      0.97      0.97        38\n",
      "   weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classificator = RandomForestClassifier(criterion='gini', n_estimators=20, n_jobs=-1)\n",
    "classificator.fit(trainX, trainY)\n",
    "predict = classificator.predict(testX)\n",
    "print(confusion_matrix(testY, predict))\n",
    "print(classification_report(testY, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "XC = iris.drop(['Species'], axis = 1) #X completo\n",
    "XP = iris.drop(['SepalLengthCm', 'SepalWidthCm', 'Species'], axis=1) #X Parcial\n",
    "Y = iris['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 0.96666667 0.93333333 0.93333333 1.        ]\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(criterion='gini', n_estimators=20, n_jobs=-1)\n",
    "score = cross_val_score(RF, XC, Y, cv=5)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acuracia da Iris com todos atributos tem:\n",
      "Média: 0.96 e Desvio Padrão de +/-: 0.02\n"
     ]
    }
   ],
   "source": [
    "print('A acuracia da Iris com todos atributos tem:')\n",
    "print('Média: %0.2f e Desvio Padrão de +/-: %0.2f' % (np.mean(score), np.std(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 0.96666667 0.93333333 0.96666667 1.        ]\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(criterion='gini', n_estimators=20, n_jobs=-1)\n",
    "score = cross_val_score(RF, XP, Y, cv=5)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acuracia da Iris só com atributo da Petalas tem:\n",
      "Média: 0.97 e Desvio Padrão de +/-: 0.02\n"
     ]
    }
   ],
   "source": [
    "print('A acuracia da Iris só com atributo da Petalas tem:')\n",
    "print('Média: %0.2f e Desvio Padrão de +/-: %0.2f' % (np.mean(score), np.std(score)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
